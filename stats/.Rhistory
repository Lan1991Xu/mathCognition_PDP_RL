rnorm(10)
gas = 50000 * 4
gas1 = (50000 / 10) * 4
gas2 = (50000/ 50) * 4
car1 = 15000
cars = 30000
car1 + gas1
car2 + gas2
cars + gas2
3^5
3 ** 5
2 ** 3 + 2 ** 4 + 2 ** 6
2 ** 2 + 2 ** 3 + 2 ** 6
c(23, 45, 67, 46, 57, 23, 83, 59, 12, 64)
summary(c)
data = c(23, 45, 67, 46, 57, 23, 83, 59, 12, 64)
summary (data)
mean(data)
a = rnorm(100)
b = rnorm(100) + a
plot (a,b)
corr(a,b)
cor(a,b)
help lm
help cor
cor
lm(b~a)
help lm
help(lm)
help(line)
help(abline)
res = lm(b~a)
res
res[2]
res
res(2)
res.Coefficients
res$Coefficients
Coefficients
res$Coefficients
ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
lm.D9 <- lm(weight ~ group)
lm.D90 <- lm(weight ~ group - 1) # omitting intercept
anova(lm.D9)
summary(lm.D90)
opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(lm.D9, las = 1)      # Residuals, Fitted, ...
par(opar)
install.packages("ggplot2")
install.packages("lattice")
? qplot
?? qplot
mtcars
head(mtcars)
qplot(mpg, disp, data = mtcars)
data = mtcats
data = mtcars
m = mtcars
qplot
installed.packages("ggplot2")
library(ggplot2)
qplot(mpg, disp, data = mtcars)
? sample
load(url("http://s3.amazonaws.com/assets.datacamp.com/course/dasi/inference.Rdata"))
inference
inference()
? by
head(mtcars)
by(mtcars$am, mtcars$mpg, mean)
head(mtcars)
by(mtcars$vs, mtcars$mpg, mean)
mtcars
summary(mtcars)
rm(list = ls())
library(ggplot2)
library(ggdendro)
PROJECT_DIR = '/Users/Qihong/Dropbox/github/PDPmodel_Categorization'
# you need to enter the file name and folder name here!
DATA_FOLDER = 'sim16_large'
FILENAME = 'hiddenFinal_e3.txt'
# load the data
datapath = paste(PROJECT_DIR, DATA_FOLDER, FILENAME, sep="/")
temp = read.table(datapath)
# set some parameters
n = length(temp)
numPatterns = dim(temp)[1]
# convert the hidden activation to a matrix
hiddenData = as.matrix(temp[1:numPatterns,4:n])
temp = as.vector(temp[1:numPatterns,2])
temp = sapply(strsplit(temp, split='l', fixed=TRUE), function(x) (x[2]))
row.names(hiddenData) = temp
# Analysis for full data (verbal + visual)
# compute the dissimilarity structure
plot.new()
par(mfrow = c(1,1))
distanceMatrix = (as.matrix(dist(hiddenData)))
image(distanceMatrix[numPatterns:1,], zlim = c(0,5.5),
col = heat.colors(10, 1), yaxt = "n", xaxt = "n")
# mtext(row.names(hiddenData))
plot.new()
lowerTriangularIndices = lower.tri(distanceMatrix)
range (distanceMatrix[lowerTriangularIndices])
image(distanceMatrix[numPatterns:1,], zlim = c(0,5.5),
col = heat.colors(10, 1), yaxt = "n", xaxt = "n")
# hclust
# par(mfrow = c(1,2))
par(mfrow = c(1,1))
plot(hclust(dist(hiddenData)),
main = 'Hierarchical clustering: hidden layer \nneural representations for all instances',
xlab = 'instances', ylab = 'distance')
# hc <- hclust(dist(hiddenData), "ave")
hc <- hclust(dist(hiddenData), "ave")
ggdendrogram(hc, rotate = FALSE, size = 2) + ggtitle("Hierarchical clustering: hidden layer \nneural representations for all instances")
hiddenMDS = cmdscale(distanceMatrix)
# check the range
range = max(abs(hiddenMDS));
plot(hiddenMDS,
main = 'MDS: hidden layer neural\n representations for all instances',
xlab = 'distance', ylab = 'distance',type = 'n',
xlim = c(-range,range), ylim = c(-range,range))
text(hiddenMDS,labels = row.names(hiddenData))
plot(as.phylo(hc), type = "fan")
library(ape)
plot(as.phylo(hc), type = "fan")
plot(as.phylo(hc), type = "fan", offset = 0.5)
plot(as.phylo(hc), type = "fan", offset = 1)
? plot
plot(as.phylo(hc), type = "fan", offset = 1)
plot(as.phylo(hc), type = "fan")
plot(as.phylo(hc), type = "fan", main = 'Hierarchical clustering: hidden layer \nneural representations for all instances')
par(mfrow = c(1,1))
plot(hclust(dist(hiddenData)),
main = 'Hierarchical clustering: hidden layer \nneural representations for all instances',
xlab = 'instances', ylab = 'distance')
hc <- hclust(dist(hiddenData), "ave")
ggdendrogram(hc, rotate = FALSE, size = 2) + ggtitle("Hierarchical clustering: hidden layer \nneural representations for all instances")
plot(as.phylo(hc), type = "fan", main = 'Hierarchical clustering: hidden layer \nneural representations for all instances')
par(mfrow = c(1,1))
plot(hclust(dist(hiddenData)),
main = 'Hierarchical clustering: hidden layer \nneural representations for all instances',
xlab = 'instances', ylab = 'distance')
hc <- hclust(dist(hiddenData), "ave")
ggdendrogram(hc, rotate = FALSE, size = 2) + ggtitle("Hierarchical clustering: hidden layer \nneural representations for all instances")
plot(as.phylo(hc), type = "fan", main = 'Hierarchical clustering: hidden layer \nneural representations for all instances')
# 2D MDS
hiddenMDS = cmdscale(distanceMatrix)
# check the range
range = max(abs(hiddenMDS));
plot(hiddenMDS,
main = 'MDS: hidden layer neural\n representations for all instances',
xlab = 'distance', ylab = 'distance',type = 'n',
xlim = c(-range,range), ylim = c(-range,range))
text(hiddenMDS,labels = row.names(hiddenData))
ls
setwd("~/")
ls
ls()
getwd()
library(dplyr)
library(tidyr)
library(tidyr)
library(dplyr)
library(ggplot2)
sessionInfo()
a <- ggplot(mpg, aes(hwy))
a + geom_area(stat = "bin")
names(d)
d <- read.csv("janiszewski_rep_cleaned.csv")
sessionInfo()
a + geom_density(kernel = "gaussian")
a
mpg
head(mpg)
aes+(hwgye))om_dotplot()
a + geom_jitter()
a + geom_dotplot
a <- ggplot(mpg, aes(hwy))
a + geom_dotplot
a + geom_freqpoly()
a + geom_density(kernel = "gaussian")
a + geom_freqpoly()
a + geom_density(kernel = "gaussian")
a + geom_area(stat = "bin")
a + geom_freqpoly()
a + geom_area(stat = "bin")
install.packages("ggplot2")
install.packages("ggplot2")
x
x = c(1,0,0)
x = logical(x)
x
# analyze the relation between gamma values and model performance
rm(list = ls())
library(ggplot2)
source('multiplot.R')
# load data
setwd('/Users/Qihong/Dropbox/github/mathCognition/stats')
mydata = read.csv('punFacData.csv', header = F)
colnames(mydata) = c('gamma', 'meanSteps', 'monoRate', 'compRate', 'correctCompRate', 'skipRate',
'steps1', 'steps2', 'steps3', 'steps4', 'steps5', 'steps6', 'steps7',
'CR1','CR2','CR3','CR4','CR5','CR6','CR7',
'CCR1','CCR2','CCR3','CCR4','CCR5','CCR6','CCR7')
head(mydata)
# analyze the relation between gamma values and model performance
rm(list = ls())
library(ggplot2)
source('multiplot.R')
# load data
setwd('/Users/Qihong/Dropbox/github/mathCognition/stats')
mydata = read.csv('punFacData.csv', header = F)
colnames(mydata) = c('gamma', 'meanSteps', 'monoRate', 'compRate', 'correctCompRate', 'skipRate',
'steps1', 'steps2', 'steps3', 'steps4', 'steps5', 'steps6', 'steps7',
'CR1','CR2','CR3','CR4','CR5','CR6','CR7',
'CCR1','CCR2','CCR3','CCR4','CCR5','CCR6','CCR7')
# visualize data
p1 = ggplot(mydata, aes(x=gamma, y=meanSteps)) +
geom_point(aes(gamma)) +
geom_smooth()
p2 = ggplot(mydata, aes(x=gamma, y=monoRate)) +
geom_point(aes(gamma)) +
geom_smooth()
p3 = ggplot(mydata, aes(x=gamma, y=compRate)) +
geom_point(aes(gamma)) +
geom_smooth()
p4 = ggplot(mydata, aes(x=gamma, y=correctCompRate)) +
geom_point(aes(gamma)) +
geom_smooth()
p5 = ggplot(mydata, aes(x=gamma, y=skipRate)) +
geom_point(aes(gamma)) +
geom_smooth()
multiplot(p1, p2, p3, p4, p5, cols=2)
geom_point(aes(gamma)) +
source('analyzeGamma.R')
# analyze the relation between parameter values and model performance
rm(list = ls())
library(ggplot2)
source('multiplot.R')
# load data
setwd('/Users/Qihong/Dropbox/github/mathCognition/stats')
mydata = read.csv('punFacData.csv', header = F)
colnames(mydata) = c('parameter', 'meanSteps', 'monoRate', 'compRate', 'correctCompRate', 'skipRate',
'steps1', 'steps2', 'steps3', 'steps4', 'steps5', 'steps6', 'steps7',
'CR1','CR2','CR3','CR4','CR5','CR6','CR7',
'CCR1','CCR2','CCR3','CCR4','CCR5','CCR6','CCR7')
# visualize data
p1 = ggplot(mydata, aes(x=parameter, y=meanSteps)) +
geom_point(aes(parameter)) +
geom_smooth() +
labs(x = "punnishFactorDecrementRate", y = "mean steps used")
p2 = ggplot(mydata, aes(x=parameter, y=monoRate)) +
geom_point(aes(parameter)) +
geom_smooth() +
labs(x = "punnishFactorDecrementRate", y = "monotonic rate")
p3 = ggplot(mydata, aes(x=parameter, y=compRate)) +
geom_point(aes(parameter)) +
geom_smooth()
p4 = ggplot(mydata, aes(x=parameter, y=correctCompRate)) +
geom_point(aes(parameter)) +
geom_smooth()
p5 = ggplot(mydata, aes(x=parameter, y=skipRate)) +
geom_point(aes(parameter)) +
geom_smooth()
multiplot(p1, p2, p3, p4, p5, cols=2)
# analyze the relation between parameter values and model performance
rm(list = ls())
library(ggplot2)
source('multiplot.R')
# load data
setwd('/Users/Qihong/Dropbox/github/mathCognition/stats')
mydata = read.csv('punFacData.csv', header = F)
colnames(mydata) = c('parameter', 'meanSteps', 'monoRate', 'compRate', 'correctCompRate', 'skipRate',
'steps1', 'steps2', 'steps3', 'steps4', 'steps5', 'steps6', 'steps7',
'CR1','CR2','CR3','CR4','CR5','CR6','CR7',
'CCR1','CCR2','CCR3','CCR4','CCR5','CCR6','CCR7')
# visualize data
p1 = ggplot(mydata, aes(x=parameter, y=meanSteps)) +
geom_point(aes(parameter)) +
geom_smooth()
#     labs(x = "punnishFactorDecrementRate", y = "mean steps used")
p2 = ggplot(mydata, aes(x=parameter, y=monoRate)) +
geom_point(aes(parameter)) +
geom_smooth()
#     labs(x = "punnishFactorDecrementRate", y = "monotonic rate")
p3 = ggplot(mydata, aes(x=parameter, y=compRate)) +
geom_point(aes(parameter)) +
geom_smooth()
p4 = ggplot(mydata, aes(x=parameter, y=correctCompRate)) +
geom_point(aes(parameter)) +
geom_smooth()
p5 = ggplot(mydata, aes(x=parameter, y=skipRate)) +
geom_point(aes(parameter)) +
geom_smooth()
multiplot(p1, p2, p3, p4, p5, cols=2)
# mean steps used by cardinality
p1 = ggplot(mydata, aes(x=parameter, y=steps1)) +
geom_point(aes(parameter)) + ylim(0, 100) +
geom_smooth()
p2 = ggplot(mydata, aes(x=parameter, y=steps2)) +
geom_point(aes(parameter)) + ylim(0, 100) +
geom_smooth()
p3 = ggplot(mydata, aes(x=parameter, y=steps3)) +
geom_point(aes(parameter)) + ylim(0, 100) +
geom_smooth()
p4 = ggplot(mydata, aes(x=parameter, y=steps4)) +
geom_point(aes(parameter)) + ylim(0, 100) +
geom_smooth()
p5 = ggplot(mydata, aes(x=parameter, y=steps5)) +
geom_point(aes(parameter)) + ylim(0, 100) +
geom_smooth()
p6 = ggplot(mydata, aes(x=parameter, y=steps6)) +
geom_point(aes(parameter)) + ylim(0, 100) +
geom_smooth()
p7 = ggplot(mydata, aes(x=parameter, y=steps7)) +
geom_point(aes(parameter)) + ylim(0, 100) +
geom_smooth()
p8 = ggplot(mydata) +
geom_smooth(aes(parameter,steps1), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,steps2), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,steps3), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,steps4), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,steps5), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,steps6), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,steps7), colour="blue", se=TRUE) +
ylim(0, 100) +
labs(x = "parameter", y = "Number of steps used on average")
multiplot(p1, p2, p3, p4, p5, p6, p7, p8, cols=3)
p1 = ggplot(mydata, aes(x=parameter, y=CR1)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p2 = ggplot(mydata, aes(x=parameter, y=CR2)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p3 = ggplot(mydata, aes(x=parameter, y=CR3)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p4 = ggplot(mydata, aes(x=parameter, y=CR4)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p5 = ggplot(mydata, aes(x=parameter, y=CR5)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p6 = ggplot(mydata, aes(x=parameter, y=CR6)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p7 = ggplot(mydata, aes(x=parameter, y=CR7)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p8 = ggplot(mydata) +
geom_smooth(aes(parameter,CR1), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CR2), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CR3), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CR4), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CR5), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CR6), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CR7), colour="blue", se=TRUE) +
ylim(0, 1) +
labs(x = "parameter", y = "Complete rate")
multiplot(p1, p2, p3, p4, p5, p6, p7, p8, cols=3)
p1 = ggplot(mydata, aes(x=parameter, y=CCR1)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p2 = ggplot(mydata, aes(x=parameter, y=CCR2)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p3 = ggplot(mydata, aes(x=parameter, y=CCR3)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p4 = ggplot(mydata, aes(x=parameter, y=CCR4)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p5 = ggplot(mydata, aes(x=parameter, y=CCR5)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p6 = ggplot(mydata, aes(x=parameter, y=CCR6)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p7 = ggplot(mydata, aes(x=parameter, y=CCR7)) +
geom_point(aes(parameter)) + ylim(0, 1) +
geom_smooth()
p8 = ggplot(mydata) +
geom_smooth(aes(parameter,CCR1), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CCR2), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CCR3), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CCR4), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CCR5), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CCR6), colour="blue", se=TRUE) +
geom_smooth(aes(parameter,CCR7), colour="blue", se=TRUE) +
ylim(0, 1) +
labs(x = "parameter", y = "Correct complete rate")
multiplot(p1, p2, p3, p4, p5, p6, p7, p8, cols=3)
